<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alma Anderson | almaan</title>
    <link>/author/alma-anderson/</link>
      <atom:link href="/author/alma-anderson/index.xml" rel="self" type="application/rss+xml" />
    <description>Alma Anderson</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 19 Jan 2021 15:01:37 +0100</lastBuildDate>
    <image>
      <url>/author/alma-anderson/avatar_hu27f7dc34c9db8fd2b063f3fba6be9864_197873_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Alma Anderson</title>
      <link>/author/alma-anderson/</link>
    </image>
    
    <item>
      <title>Paper Review | Toward a Common Coordinate Framework for the Human Body</title>
      <link>/post/2021-01-19-ccf-rev/</link>
      <pubDate>Tue, 19 Jan 2021 15:01:37 +0100</pubDate>
      <guid>/post/2021-01-19-ccf-rev/</guid>
      <description>&lt;p&gt;For quite some while now, I&amp;rsquo;ve carried a slight sensation of guilt within me.
Guilt for being so caught up in my own projects and activities that I&amp;rsquo;ve come to
neglect one of the most essential duties as a researcher: to survey, read, and
contemplate upon new (and old) material that have been published. It&amp;rsquo;s so easy
to put that interesting paper aside in order to finish a project deadline, as no
immediate gains are observed from reading through the former in contrast to
completing the latter. Once a habit, this behavior efficiently imprints the idea
that &amp;ldquo;making&amp;rdquo; is more important than learning; this might give a false sense of
efficiency at first, but (I believe) has a severe negative impact on the quality
and creativity of one&amp;rsquo;s work in the long run. How am one supposed to grow and
expand the knowledge sphere if one never travels beyond its borders? Hence, I&amp;rsquo;ve
somehow managed to conjure a vision of myself being a more active &lt;del&gt;reader&lt;/del&gt;
gatherer of information this year by committing to the task of doing bi-weekly
paper reviews, starting today. I should say here, that these reviews will mainly
be focused on &lt;em&gt;summarizing&lt;/em&gt; the material presented, rather than &lt;em&gt;evaluating&lt;/em&gt;
them; but of course, if I have opinions or comments which I deem relevant, these
will be shared as well. My hope is to continue this at least throughout the
year, to then evaluate and reassess whether its an endeavor worth continuing.
Alas, let&amp;rsquo;s get started.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Paper Title :&lt;/strong&gt; &lt;em&gt;Toward a Common Coordinate Framework for the Human Body&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Authors :&lt;/strong&gt; &lt;em&gt;Jennifer E. Rood, Tim Stuart, Shila Ghazanfar, Tommaso
Biancalani, Eyal Fisher, Andrew Butler, Anna Hupalowska, Leslie Gaffney, William
Mauck, Gökçen Eraslan, John C. Marioni, Aviv Regev, Rahul Satija&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Published :&lt;/strong&gt; 12-12-2019&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;doi :&lt;/strong&gt; &lt;a href=&#34;https://doi.org/10.1016/j.cell.2019.11.019&#34;&gt;https://doi.org/10.1016/j.cell.2019.11.019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Review&lt;/strong&gt;: In ambitious projects like the &lt;a href=&#34;https://www.humancellatlas.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Human Cell
Atlas&lt;/a&gt; we often rely on joint efforts from
multiple labs, as well as collection of data across multiple individuals, ages,
phenotypes, both sexes and plenty of other features. This strategy is very apt
for producing &lt;em&gt;large and diverse&lt;/em&gt; datasets; but unless we somehow harmonize and
integrate all of the data into a common framework it will be nothing more than a
big mess that is ought to bring more headaches than joy. The
authors of this paper discuss these issues in terms of a &lt;strong&gt;common coordinate framework&lt;/strong&gt;
which they - very neatly - define as a reference map that can : &amp;ldquo;&lt;em&gt;[..] assign a
reproducible address to every location&lt;/em&gt;&amp;rdquo;. CCFs can be constructed at different
scales (macro, meso, micro and fine are used as examples here), but its purpose
always remains the same, to relate regions in independent samples in a shared context.&lt;/p&gt;
&lt;p&gt;Personally, I think it&amp;rsquo;s easiest to motivate the need of a CCF through an
analogy. Imagine you have a set of portraits, painted by different artists. Some
paintings depict the same individual, but not all of them. An example of this
scenario is illustrated below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;good-v-bad.png&#34; alt=&#34;NaN&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now, if we wanted to assess how skilled each painter was at recreating certain
facial features (e.g., eyes or noses), we must somehow identify these different
parts in each of the pictures before we could speak of comparing them. However,
it&amp;rsquo;s insufficient to only compare the images pixel-by-pixel as we have several
different motifs. Somehow, we need to use the &lt;em&gt;common&lt;/em&gt; features of a face, to
identify the &lt;em&gt;unique&lt;/em&gt; elements of each artist. Similarly, when building an atlas
of the human body, organs or sub-region of an organ using data from multiple
sources, we need to know where each piece fits into the larger picture. A CCF
would further enable a very precise exploration of variation across individuals,
and is obviously a fundamental tool in any quest to study heterogeneity.&lt;/p&gt;
&lt;p&gt;In the paper they discuss some of the challenges associated with the
creation of a CCF, and consider the inherent anatomical diversity across
individuals as perhaps the most prominent one. They also bring up a good point
about how consistent annotation (used to assemble the CCF) is not as
straightforward of a task as it might seem, since biological compartments and structures do not
always have well-defined boundaries. Another challenge in devising methods to
construct CCFs arise from the fact that a sample&amp;rsquo;s character by and large
dictates how appropriate a certain method is. To illustrate this, two extremes
are given as examples: (1) when anatomical regions are highly similar across all
samples (e.g., early stages of embryogenesis), and (2) when cells are
(seemingly) randomly organized (for example in a tumor). Of course, these two
extremes represent end-points on a continuum, and most samples place somewhere
in-between the two. For samples more like (1) leveraging the consistency and &lt;em&gt;a
priori&lt;/em&gt; knowledge is preferable, while for samples like (2) one would instead do
better by employing data-driven methods where the locations are learnt from the
data. Of course, in both scenarios it is appealing to envision a form of
Bayesian approach, where we update our beliefs regarding a sample&amp;rsquo;s location as
more data is gathered.&lt;/p&gt;
&lt;p&gt;Different variants of CCFs exist, three broad classes are
given in the paper: using Anatomical Plane Coordinates, Landmark based
construction and complex non-standard approaches. The first (anatomical plane
coordinates) more or less aligns samples by registration to a reference (to account for
inter-specimen variation). It uses a standard coordinate axis as the reference
point to which distances are measured. One huge benefit is that distances
between objects in this space, represent true distances. The landmark
based approach is more or less an extension of the anatomical plane coordinates,
but where one uses known landmarks (e.g., a vein bifurcation or a certain axon
bundle) rather than anatomical planes. These landmarks allow one to anchor
points in different samples to a reference. Having identified the landmarks, one
may then apply a linear transformation to map a query image to the reference.
For both the aforementioned strategies, the use of a &lt;em&gt;reference&lt;/em&gt; is
essential - the template itself may however be updated iteratively as the process
progress. The complex non-standard approaches are used when there&amp;rsquo;s a lack
of anatomical structure or when no clear landmarks can be identified. In complex
approaches, local non-linear (in contrast to the other methods) warping is
applied to account for large anatomical variation.&lt;/p&gt;
&lt;p&gt;Now of course, as you might have noted, both of the two first methods relies on
a reference template. Hence the question of how such a template is
obtained, to which the authors answers that it depends largely on the sample.
For &lt;strong&gt;highly stereotypical&lt;/strong&gt; samples, a successful approach has been to use an
iterative process, starting with a seeding set to which the whole dataset is
aligned, a new reference is then extracted and used as a seed
in the next iteration; a procedure repeated until convergence. To
overcome the inter-individual variability in samples with &amp;ldquo;&lt;em&gt;similar
inter-individual organ structure but differences in cell type location and organ
dimensions&lt;/em&gt;&amp;rdquo; a certain degree of supervision was added to the procedure; by
manual annotation of landmarks etc. Semi-supervised processes are also predicted
to be of great use in the construction of a human atlas. For highly
&lt;strong&gt;non-stereotypical&lt;/strong&gt; samples, there were no good strategies for template
construction at the date of their writing, and they mention how this will have
to be remedied by new methodological developments.&lt;/p&gt;
&lt;p&gt;Interestingly the authors highlight a fourth orthogonal, and fairly
unconventional, approach that discards the use of a &lt;em&gt;pre-defined&lt;/em&gt; coordinate
system, landmarks and templates, in favor of learning it from the data itself.
Multiple examples of methods for spatial reconstruction (see Seurat v3
and novoSpaRc) can be seen as testimonies to spatial information being contained
within the expression profiles of cells. To me, this is very similar to the SLAM
problem in robot localization, where one tries to create the map while also
finding ones current position within it.&lt;/p&gt;
&lt;p&gt;They also discuss how, once a CCF is established, samples of the same and
different modalities may be mapped to it. If we are operating with data of the
same modality, the process should be nothing but straightforward. We simply use
the same strategy as when creating the CCF itself. For other
cross-modality-mapping the case is slightly different, and integration will only
be possible if the assumption that both modalities shares a latent
representation (e.g., chromatin accessibility) holds.&lt;/p&gt;
&lt;p&gt;Now, one idea that the authors introduce, and which according to them is novel
(I can find nothing that would contradict the claim) is that given all these
challenges and how much influence a sample&amp;rsquo;s character has on the choice of
method, is to dismiss the objective of creating a single CCF. Instead, multiple
CCFs should be created in a hierarchical (by scale) fashion, which would allow
both horizontal and vertical movements across the atlas, but where each CCF is
adapted to best fit the data. This would represent a sort of &amp;ldquo;atlas of atlases&amp;rdquo;
as they express it. To me, this makes perfect sense, although it would
have been interesting to see some more discussion of how the vertical movements
(between scales) were envisioned.&lt;/p&gt;
&lt;p&gt;Their conclusions are brief, and so shall mine be. They make a strong argument
for the value of CCFs, and why they deserve our attention.
Inter-individual variability is the biggest hurdle to tackle, but there are
strategies for it, though highly dependent on the data; this is not a &amp;ldquo;one-size
fits all&amp;rdquo; type of problem. When the data is complex and we can&amp;rsquo;t establish
natural anatomical templates or find good landmarks, perhaps it&amp;rsquo;s better to let
the data dictate its own reference, using approaches inspired from methods of
spatial reconstruction. All in all, CCFs brings structure to a very chaotic and
seemingly unstructured space - and they are imperative to the process of
creating a unified atlas of the human body.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Models and automated cell tracking</title>
      <link>/post/2021-01-08-celltracker/</link>
      <pubDate>Fri, 08 Jan 2021 10:25:51 +0100</pubDate>
      <guid>/post/2021-01-08-celltracker/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve always found it appealing, or rather &lt;em&gt;enticing&lt;/em&gt;, to study biological
systems from a more formal and mathematical perspective; with the main objective
to somehow be able to describe them with equations rather than words. Equations
are exact, definite, universal, but foremost, they are &lt;em&gt;predictive&lt;/em&gt;. The
alluring property of mathematical models is that they do not only provide a
description of our system, but they are also responsive, we may ask &lt;em&gt;&amp;ldquo;if I
replace parameter X with parameter Y, what will my system look like?&amp;quot;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course, our models - however beautiful or carefully constructed - are nothing
but just that, models. And as the well known apohorism states, &lt;em&gt;&amp;ldquo;all models
are wrong&amp;rdquo;&lt;/em&gt;. While this statement is true, it is far from detrimental.
Sometimes, being wrong but within a certain marginal of error to the truth is
just about good enough. When driving, none of us knows the exact distance to the
other cars, or how much a push on the gas will accelerate our car, still (most
of the time) we manage to zig-zag through the densely packed lanes without
crashing into each other - all from the simple &lt;em&gt;incorrect&lt;/em&gt; model we constructed
in our minds. So, yes - models are wrong, but they are most certainly useful and
tremendously valuable in our quest to understand and analyze biological systems.&lt;/p&gt;
&lt;p&gt;It was with this interest - and a requirement for PhD students at KTH to collect
60 ECTS credits - that I enrolled for a course in Applied Estimation. In short,
the course focus on how to estimate states or parameters from noisy measurements
such as empirical data. Albeit designed for people working with robotics, the
concepts are indubitably applicable to biology - where noise is the rule
rather than the exception.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;anim.gif&#34; alt=&#34;tracking animation&#34;&gt;&lt;/p&gt;
&lt;p&gt;As a part of the course, we had to devise our own project (where one estimation
method was to used) and implement it in code. My choice fell upon a subject (and
method) that I have little previous experience with: automated &lt;em&gt;cell tracking&lt;/em&gt;
in brightfield images, using GM-PHD (Gaussian Mixture Probability Hypothesis
Density) filters. The theory is very interesting, and I was particularly
intrigued by the concept of &lt;em&gt;Random Finite Sets&lt;/em&gt;, here used to track multiple
objects simultaneously. The method shares many similarities with the Kalman
Filter, but rather than propagating a single state, the whole set is propagated
in time. Easily explained, one might think of it as propagating a Gaussian
Mixture in time, where each component represents a peak or cell. The &lt;a href=&#34;https://ieeexplore.ieee.org/document/1710358&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;original
publication&lt;/a&gt; by Vo and Ma outlines
the details of the GM-PHD filter better than I could ever attempt to, and I
would refer anyone with an interest to have a close look at it.&lt;/p&gt;
&lt;p&gt;As for the final product, I implemented the algorithm proposed by Vo and Ma
(Table I-III) in python, with an easy to use CLI; allowing anyone who might want
to try it out to do so fairly (I hope) seamlessly. Instructions and examples of
usage can be found at the &lt;a href=&#34;https://github.com/almaan/CellTracker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt; page.
The animated image above is the result of applying this implementation to a set
of &amp;ldquo;&lt;em&gt;HeLa cells stably expressing H2b-GFP&lt;/em&gt;&amp;rdquo;, downloaded from
&lt;a href=&#34;http://celltrackingchallenge.net/2d-datasets/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;celltrackingchallenge.net&lt;/a&gt;. The
implementation is far from perfect, and much work remains to even have a chance
of competing with the more sophisticated alternatives. Still, for a couple of
days of work, the performance is not too bad - and it was a fun experience
implementing it.&lt;/p&gt;
&lt;p&gt;The course has prompted a lot of new ideas and really allowed me to see some old
problems from a completely different lens. For example, I believe a lot of the
ideas found in SLAM (Simultaneous Localization and Mapping) could be used when
working with questions related to trajectory inferenc, where we partly want to
assess the developmental landscape but also map a path through it. It&amp;rsquo;s always a
very rewarding experience to enter a completely new field, where people come
from a very different background - in my opinion this intentional &amp;ldquo;push&amp;rdquo; out of
the comfort zone really has a tendency to spark &lt;del&gt;great&lt;/del&gt; exciting ideas,
however uncofortable it feels at first.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publication | Spatial Single Cell Mapping</title>
      <link>/post/stereoscope-001/initial-post/</link>
      <pubDate>Fri, 09 Oct 2020 11:05:04 +0100</pubDate>
      <guid>/post/stereoscope-001/initial-post/</guid>
      <description>&lt;p&gt;Delighted to say that our manuscript &amp;ldquo;&lt;em&gt;Single-cell and spatial transcriptomics
enables probabilistic inference of cell type topography&lt;/em&gt;&amp;rdquo; is now published in
&lt;em&gt;Communications Biology&lt;/em&gt; and thus out there for everyone to read in its final
form. This is the paper that describes the theoretical underpinnings for
&lt;a href=&#34;https://github.com/almaan/stereoscope&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stereoscope&lt;/a&gt;, which allows you to
spatial map cell types found in single cell data onto spatial transcriptomics
data. There is also a nice bit of discussion as to whether spatial
transcriptomics data (ST/Visium) can be properly modeled using a negative
binomial distribution (which we use) found in the supplementary (spoiler, it
seems like it). Have a look at it if you are interested!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;manuscript link : &lt;a href=&#34;https://www.nature.com/articles/s42003-020-01247-y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HERE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;stereoscope link : &lt;a href=&#34;https://github.com/almaan/stereoscope&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HERE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;P.S: I&amp;rsquo;m also planning to update the code base in the future, providing an API for
&lt;code&gt;scanpy&lt;/code&gt;, but also add some features like subsampling and gene selection to the
standard modules; but that is for later.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Manuscript | Spatial Exploration of Her2 Breast Cancer</title>
      <link>/post/her2-001/initial-post/</link>
      <pubDate>Wed, 15 Jul 2020 11:05:04 +0100</pubDate>
      <guid>/post/her2-001/initial-post/</guid>
      <description>&lt;p&gt;We&amp;rsquo;ve put out a new
&lt;a href=&#34;%22https://www.biorxiv.org/content/10.1101/2020.07.14.200600v1.article-metrics%22&#34;&gt;manuscript&lt;/a&gt; on bioRxiv, where the expression landscape of HER2-positive
breast cancer tumors is studied from a spatial perspective. This study contains
several examples of how spatial data may be analyzed and what information beyond
the obvious - like the spatial distribution of a certain gene - that can be
mined from it. My hope is that anyone looking for ideas regarding how to analyze
their own spatial data find this useful and relevant, irregardles of their
interest in breast cancer. In the study we cluster spots by gene expression, but
also take this one step further, using the clusters to find &lt;i&gt;core
signatures&lt;/i&gt; of immune and tumor cell populations within our samples. We also
use &lt;i&gt;stereoscope&lt;/i&gt; to map single cell data down onto our tissue sections,
information which then is used to indentify potential TLS-sites as well as to
study patterns of cell type co-localization. All the scripts and a neat app for
visualization of the results can be found &lt;a href=&#34;%22https://github.com/almaan/her2st/%22&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resource | Formal systems in Biology</title>
      <link>/post/synt-bio-001/initial-post/</link>
      <pubDate>Wed, 01 Jul 2020 10:05:04 +0100</pubDate>
      <guid>/post/synt-bio-001/initial-post/</guid>
      <description>&lt;p&gt;Browsing through my daily feed, I stumbled upon
&lt;a href=&#34;%22https://github.com/prathyvsh/formal-systems-in-biology%22target=%22_blank%22&#34;&gt;this&lt;/a&gt;
neat resource which lists (and links to) fundamental ideas that have shaped the
field of systems biology. To me, many of these publications represent some of
the earliest attempts to reduce complex biological systems and processes into
something simpler, more comprehensible, by viewing them through the lense of
mathematics; truly groundbreaking efforts that paved the way for the current
trends of ML/AI in biology. I&amp;rsquo;d strongly recommend anyone with an interest in
the field to have a look at it; something that contains work from both Alan
Turing and John von Neumann can&amp;rsquo;t be anything but good!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
