<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>2025 Western States 100 | Alma Andersson</title>
<meta name="title" content="2025 Western States 100" />
<meta name="description" content="&#x1f44b; Introduction At 5:00 a.m. PT on June 28th, 2025, 369 lucky runners will start the Western States 100, one of American ultrarunning‚Äôs most iconic races. The 100.2-mile (161 km) course winds from Olympic Valley, near Palisades Tahoe, to a high school track in Auburn, California.
The race has made legends ‚Äî and broken hearts. Entry comes via a lottery system or a coveted ‚ÄúGolden Ticket‚Äù that has to be won from fiercely competitive qualifiers." />
<meta name="keywords" content="random,running,RNN,Western States,GRU," />


<meta property="og:url" content="https://almaan.github.io/blog/2025-05-25-wse/">
  <meta property="og:site_name" content="Alma Andersson">
  <meta property="og:title" content="2025 Western States 100">
  <meta property="og:description" content="üëã Introduction At 5:00 a.m. PT on June 28th, 2025, 369 lucky runners will start the Western States 100, one of American ultrarunning‚Äôs most iconic races. The 100.2-mile (161 km) course winds from Olympic Valley, near Palisades Tahoe, to a high school track in Auburn, California.
The race has made legends ‚Äî and broken hearts. Entry comes via a lottery system or a coveted ‚ÄúGolden Ticket‚Äù that has to be won from fiercely competitive qualifiers.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-05-24T00:53:05+01:00">
    <meta property="article:modified_time" content="2025-05-24T00:53:05+01:00">
    <meta property="article:tag" content="Random">
    <meta property="article:tag" content="Running">
    <meta property="article:tag" content="RNN">
    <meta property="article:tag" content="Western States">
    <meta property="article:tag" content="GRU">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025 Western States 100">
  <meta name="twitter:description" content="üëã Introduction At 5:00 a.m. PT on June 28th, 2025, 369 lucky runners will start the Western States 100, one of American ultrarunning‚Äôs most iconic races. The 100.2-mile (161 km) course winds from Olympic Valley, near Palisades Tahoe, to a high school track in Auburn, California.
The race has made legends ‚Äî and broken hearts. Entry comes via a lottery system or a coveted ‚ÄúGolden Ticket‚Äù that has to be won from fiercely competitive qualifiers.">




  <meta itemprop="name" content="2025 Western States 100">
  <meta itemprop="description" content="üëã Introduction At 5:00 a.m. PT on June 28th, 2025, 369 lucky runners will start the Western States 100, one of American ultrarunning‚Äôs most iconic races. The 100.2-mile (161 km) course winds from Olympic Valley, near Palisades Tahoe, to a high school track in Auburn, California.
The race has made legends ‚Äî and broken hearts. Entry comes via a lottery system or a coveted ‚ÄúGolden Ticket‚Äù that has to be won from fiercely competitive qualifiers.">
  <meta itemprop="datePublished" content="2025-05-24T00:53:05+01:00">
  <meta itemprop="dateModified" content="2025-05-24T00:53:05+01:00">
  <meta itemprop="wordCount" content="1857">
  <meta itemprop="keywords" content="Random,Running,RNN,Western States,GRU">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }
</style>

    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'],['$','$']]                  
    }
  };
</script>

  

  
</head>

<body>
  <header><a href="/" class="title">
  <h2>Alma Andersson</h2>
</a>
<nav><a href="/">Home</a>


<a href="/blog">Blog</a>

</nav>
</header>
  <main>

<h1>2025 Western States 100</h1>
<p>
  <i>
    <time datetime='2025-05-24' pubdate>
      24 May, 2025
    </time>
  </i>
</p>

<content>
  <h3 id="wave-introduction">&#x1f44b; Introduction</h3>
<p>At 5:00 a.m. PT on June 28th, 2025, 369 lucky runners will start the <a href="https://en.wikipedia.org/wiki/Western_States_Endurance_Run">Western
States 100</a>, one of American
ultrarunning‚Äôs most iconic races. The 100.2-mile (161 km) course winds from
Olympic Valley, near Palisades Tahoe, to a high school track in Auburn,
California.</p>
<p>The race has made legends ‚Äî and <a href="https://www.youtube.com/watch?app=desktop&amp;v=DZb7jBYL9y8&amp;t=0s">broken
hearts</a>. Entry
comes via a lottery system or a coveted ‚ÄúGolden Ticket‚Äù that has to be won from fiercely
competitive qualifiers. The race has inspired numerous documentaries, including
the classic <a href="https://www.youtube.com/watch?v=zy1as6CTYXI">&ldquo;Unbreakable&rdquo;</a>, which
chronicles the dramatic 2010 edition.</p>
<p>This year looks <em>stacked</em>: 2010 stars are returning, Killian Jornet is back, and a
deep elite field is set for a thrilling showdown.</p>
<hr>
<h3 id="dart-task">&#x1f3af; Task</h3>
<p>While I won&rsquo;t be there to run the race (I&rsquo;d struggle to make it even halfway) ‚Äî
I still wanted to get in on the action somehow. Thinking more about it, I wanted
to see if there was a way to build some form of forecasting model; more
specifically, given a runner&rsquo;s times at the previous aid stations, can we
predict the time to a future distance (e.g., the next aid station)?</p>
<p>Now, during most races, they often present an estimated finish time, which is
usually a prediction based on the current pace ‚Äî that is, it answers the
question: <em>&ldquo;If the runner kept on going at the same pace, when would they
finish?&rdquo;</em>. This is <strong>not</strong> what I wanted to build. I wanted something that takes
in the full context of a runner&rsquo;s journey. Perhaps being fast on a certain
uphill segment or slowing down over a certain part of the course is highly
informative of how you will perform on much later segments; this is not captured
in the linear interpolation of pace.</p>
<p>I have no idea what those &ldquo;indicators of later performance&rdquo; might be, but in
theory, we should be able to <strong>learn them from the data</strong>. So, I decided to find
out if this was possible. That is, my goal became: to build a forecasting model
specifically designed for Western States predictions.</p>
<hr>
<h3 id="point_down-execution">&#x1f447; Execution</h3>
<h4 id="wrench-data-curation">&#x1f527; Data curation</h4>
<p>I started by downloading the splits from the official WSE (Western States
Endurance) <a href="https://www.wser.org/splits/">page</a>. This data required some
curation that involved harmonizing the aid station names, filtering the data,
cleaning up, and formatting in the data. In the end, I ended up with a pretty
neat dataset of <strong>2271</strong> runs between 2017-2024.</p>
<p><em>Note</em>: some technical jargong,
I&rsquo;m going to refer to an individual run (e.g., Person X&rsquo;s run in 2016) as a
<em>trajectory</em>. Visualizing all of these together was a mess, but here are 20 randomly sampled trajectories:</p>
<p><img src="imgs/trajectories.png" alt="trajectory sample"></p>
<p>Another way to visualize the full dataset is in a heatmap style, where the
intensity corresponds to how much time that have elapsed; if we sort the
trajectories by finish time, we end up with a pretty nice visualization (white
means no time was registered at the corresponding aid station):</p>
<p><img src="imgs/times.png" alt="heatmap"></p>
<p>You can see how the intensity increases from the top left corner (fastest
runner, first aid station) with a diagonal gradient towards the bottom right
corner (slowest runner, last aid station).</p>
<p>This is the dataset I set out to work with.</p>
<h4 id="robot-model">&#x1f916; Model</h4>
<p>With a dataset this small, I wanted to do something very simple, so I decided
to test a classic RNN. I&rsquo;m not claiming this to be <em>the best</em> solution‚Äîit&rsquo;s just
one attempt.</p>
<p>To describe trajectory \( i \), we let \( x_s^i \) denote the distance at aid
station \( s \), and \( y_s^i(x_s) \) the elapsed time at the same aid station.
The full trajectory is then:</p>
$$
\textrm{trajectory}_i = \{(x_s, y^i(x_s))\}_{s=0}^{s=S} = \mathbf{r}_i(S)
$$<p>While the true trajectory is continuous, we treat it as discrete observations
because we only have access to elapsed time at the aid stations (no
continuous measurements).</p>
<p>The model I settled on is physics-informed and really does nothing more advanced than correcting a simple
model. This simple model predicts the time to a given aid station using the
average pace at the last aid station multiplied by the distance to the target
(middle school math for the win). The correction is an additive term learned by
an RNN, which adjusts the linear prediction. In essence, the physics-informed
model can be described as:</p>
$$\textrm{predicted time} = \textrm{last time} + \textrm{average pace}\cdot \textrm{distance} + \textrm{RNN adjustment}$$<p>or mathematically:</p>
$$y^i(x_{s'}) = y^i(x_{s'-1}) + \frac{y(x_{s'-1})}{x_{s'-1}} \cdot (x_{s'} - x_{s'-1} ) + a^i_{s'} $$$$
a^i_{s'} = \textrm{MLP}(h^i_{s'-k}, x_{s'}), \qquad
h^i_{s'-k} = \textrm{GRU}(\mathbf{r}_i(s'-k))
$$<p>Here, \( s' \) is the aid station we want to predict the time for, and \( k \)
represents the number of aid stations before \( s' \) where we have our latest
observation. For example, if we know a runner‚Äôs position at the third-to-last
aid station and want to predict their time at the finish, we&rsquo;d let \( k = 3 \).
As you can see, the RNN adjustment term is informed by all of the observed
trajectory.</p>
<p>\( \textrm{GRU} \) is a <em>gated recurrent unit</em>. The GRU layer essentially
consists of two gates: the <strong>update gate</strong> and the <strong>reset gate</strong> ‚Äî the former
controls how much of the past state to keep, and the latter how much should be
forgotten. GRUs have been around <a href="https://arxiv.org/abs/1406.1078">since 2014</a>,
but I think they are quite clever and that merits a more elaborate description. A GRU layer
can be described as follows for some input $x_s$:</p>
$$z_s = \sigma(W_z x_s + U_zh_{s-1} + b_z)$$$$q_s = \sigma(W_q x_s + U_q h_{s-1} + b_q)$$$$\hat{h}_s = \textrm{tanh}(W_h x_s + U_h(q_s \odot h_{s-1} ) + b_h)$$$$h_s = (1-z_s) \odot h_{s-1} + z_s \odot \hat{h}_s$$<p>Where $\sigma$ is the sigmoid function, $z_s$ is the update gate vector, and
$q_s$ is the reset gate vector. In short, if $z_s \mapsto 1$ we keep most of the candidate state $\hat{h}_s$, and vice versa. Similarly, if $q_s \mapsto 0$ the old state ($h_{s-1}$) is not influencing the candidate state at all.</p>
<p>As for the \( \textrm{MLP} \), I designed it as follows:</p>
$$
\text{MLP} = \text{Softplus} \circ \text{BayesLinear} \circ \text{ReLU} \circ \text{Linear}
$$<p>I used Softplus to ensure strictly positive outputs (time on course cannot
decrease); after some experimentation, it seems like this was a <em>key</em> design
element. The other unusual element might be the \( \textrm{BayesLinear} \)
layer, which initially was included because I was interested in estimating model uncertainty,
but it actually proved more useful in helping to regularize the model. The
<strong>input</strong> to the MLP layer is the <em>hidden state</em> from the GRU layer
($h^i_{s'-k}$), the <em>distance</em> of the last aid station in the observed
trajectory ($x_{s'-k}$), and the <em>distance</em> of the aid station we seek to
predict the time for ($x_{s'}$).</p>
<p>The reason I didn&rsquo;t work with fixed distances (e.g., aid stations), was because
I wanted to be able to predict the time to <em>any</em> distance.</p>
<p><em>Note:</em> This was not the first model I tried, but it was the one that worked
best.</p>
<h4 id="trident-training-splits">&#x1f531; Training Splits</h4>
<p>I decided to create train/validation/test splits based on the years. This should
allow us to evaluate robustness to distribution shifts (e.g., warm weather,
better shoes, better fueling strategies, etc.). These were the sets I came up
with:</p>
<ul>
<li>Training set: 2016, 2018, 2019, 2021, 2023</li>
<li>Validation set: 2017, 2022</li>
<li>Test set: 2024</li>
</ul>
<p>The logic? One earlier year (2016) and one later year (2022) for the validation,
and the most recent year for test set - to evaluate the ability to forecast
future races.</p>
<h4 id="zap-training">&#x26a1; Training</h4>
<p>During training, I randomly sampled a (cutoff, target) pair for each trajectory. The cutoff determines how much of the trajectory the model sees; the target is the aid station to predict elapsed time for.</p>
<p>I used a simple MSE loss on the predicted time. After some experimenting, I settled on a straightforward setup:</p>
<ul>
<li>Optimizer: Adam</li>
<li>Scheduler: <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html">CosineAnnealing</a></li>
</ul>
<p>Everything was monitored with TensorboardX.</p>
<h3 id="rocket-results">&#x1f680; Results</h3>
<p><em>Baseline:</em> For comparison, I implemented a baseline that computes a weighted
average of the observed paces, where the weights are the inverse squared
distance to the target aid station. It‚Äôs essentially the same type of
physics-informed model as the RNN-model is based on, but uses the full trajectory up to the last observed
point ‚Äî rather than just the most recent observation. To me this is a relevant
baseline to compare against: it&rsquo;s cheap (computationally) and similar to what
currently seems to be used in race time prediction.</p>
<h4 id="chart_with_downwards_trend--losses">&#x1f4c9;  Losses</h4>
<p>The model seemed to converge nicely, eventually hitting a plateau. Sampling
(cutoff, target) pairs on the fly (dark curve ) was a bit less stable than fixing
them (orange curve), but I prefer this‚Äîit acts as a form of augmentation.</p>
<p><img src="imgs/loss_curves.png" alt="loss curves"></p>
<h4 id="eyeglasses-visual-inspection">&#x1f453; Visual Inspection</h4>
<p>The very first thing I wanted to do was to inspect some of the predicted
trajectories to see if they made any sense. Here&rsquo;s an excerpt where we predict
the trajectory from the 5th, 8th, and 12th aid station.</p>
<p>Prediction from the 5th aid station:
<img src="imgs/pred_traj_step_5.png" alt="loss_curves_step12"></p>
<p>Prediction from the 8th aid station.
<img src="imgs/pred_traj_step_8.png" alt="loss_curves_step12"></p>
<p>Prediction from the 12th aid station.
<img src="imgs/pred_traj_step_12.png" alt="loss_curves_step12"></p>
<p>Important, this is all on 2024 data - <strong>the test set</strong>, which the model has
never seen. My conclusion from this was that the results were <em>not overly
impressive</em>, but not terribly bad either.</p>
<p>However, visual inspections can be deceiving so I wanted something more quantitative.</p>
<h4 id="abacus-quantitative-evaluation">&#x1f9ee; Quantitative evaluation</h4>
<p>For the quantitative evaluation I compared the RNN-based model against the
baseline by looking at the relative absolute error for each predicted step, given a
certain observed trajectory length. The picture below shows such an analysis when the
observed trajectory is up-until the 11th aid station.</p>
<p><img src="imgs/model_comp_3.png" alt="model comparison"></p>
<p>The results you see in this plot was quite representative for the analysis at
any step, where the RNN-based model does better the further away we&rsquo;re trying to
forecast. I found this somewhat promising. From this &ldquo;investigation&rdquo; it seems as
if the RNN-based model beats the baseline model in most instances (but
definitely not all).</p>
<h3 id="crystal_ball-future-directions">&#x1f52e; Future Directions</h3>
<p>This is not a research paper, so I don&rsquo;t have to pretend I intend to follow up
too much on this; but there were a few things that struck me as interesting to actually try at some point:</p>
<ul>
<li>Using <em>year</em> metadata - it would be interesting to try and condition the
model on things like temperature etc. A warm year likely has different running dynamics than a cool year.</li>
<li>Using <em>runner</em> metadata - if one could pull Strava logs or even information from races during the year leading up to the race for each runner and integrate it. I&rsquo;d be curious to see whether this would result in a significant boost in performance.</li>
<li>Generalize - currently this model only works on this particular course, but perhaps one could pull more data from other races and provide a course profile as input to make it adapt to any race.</li>
</ul>
<h4 id="thinking-concluding-remarks-aka-ramblings">&#x1f914; Concluding Remarks (a.k.a. ramblings)</h4>
<p>This was a fun project that I thoroughly enjoyed working on &ndash; probably because
it intersects two of my main interests: machine learning and running. The most
annoying part was curating and harmonizing the data, but that&rsquo;s no surprise.</p>
<p>I have not yet uploaded the code or data, but there&rsquo;s a 30-50% chance
of me doing it. If so, I&rsquo;ll update the blog post.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->

</content>
<p>
  
  <a href="https://almaan.github.io/tags/random/">#Random</a>
  
  <a href="https://almaan.github.io/tags/running/">#Running</a>
  
  <a href="https://almaan.github.io/tags/rnn/">#RNN</a>
  
  <a href="https://almaan.github.io/tags/western-states/">#Western States</a>
  
  <a href="https://almaan.github.io/tags/gru/">#GRU</a>
  
</p>

  </main>
  <footer>Made with <a href="https://github.com/janraasch/hugo-bearblog/">Hugo  ï‚Ä¢·¥•‚Ä¢ î Bear</a>
</footer>

    
</body>

</html>
