<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>reflections | almaan</title>
    <link>/tag/reflections/</link>
      <atom:link href="/tag/reflections/index.xml" rel="self" type="application/rss+xml" />
    <description>reflections</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Apr 2022 06:01:05 +0100</lastBuildDate>
    <image>
      <url>/images/icon_hu0976d26fdaec5d0ec6c053b09a4e039a_2013_512x512_fill_lanczos_center_2.png</url>
      <title>reflections</title>
      <link>/tag/reflections/</link>
    </image>
    
    <item>
      <title>Thesis Epilogue</title>
      <link>/post/2022-04-06-epilogue/</link>
      <pubDate>Wed, 06 Apr 2022 06:01:05 +0100</pubDate>
      <guid>/post/2022-04-06-epilogue/</guid>
      <description>&lt;p&gt;On the 18th of March 2022 I defended my PhD thesis: &lt;em&gt;&amp;ldquo;Computational methods for analysis of spatial transcriptomics data&amp;rdquo;&lt;/em&gt;. About a month before this date, I
finalized the actual document to be defended. Having spent a considerable amount
of time writing the thesis, I had two realizations upon submission: (1) aside
from my supervisor, the opponent, and my thesis committee - only a handful
people would at most read this thing I&amp;rsquo;ve worked so hard to compile; (2) the
part I deemed most valuable was the &lt;em&gt;Epilogue&lt;/em&gt;, where I
took the freedom to share some personal insights from these years.&lt;/p&gt;
&lt;p&gt;Hence, I&amp;rsquo;ve decided to post an excerpt from the Epilogue here on the website. I
like it not because it&amp;rsquo;s a literary masterpiece (it most certainly is not), but
because it contains advice I wish I had known when starting my PhD. It consists
of three parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What I&amp;rsquo;ve learnt&lt;/strong&gt; : lessons learnt from my time as a PhD&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What I predict&lt;/strong&gt; : some humble prediction about the future&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What I hope&lt;/strong&gt; : hopes for the future&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For anyone interested in the full thesis, it can be found &lt;a href=&#34;http://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A1639545&amp;amp;dswid=4029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;what-ive-learnt&#34;&gt;What I&amp;rsquo;ve learnt&lt;/h1&gt;
&lt;p&gt;The &lt;em&gt;&amp;ldquo;end of history illusion&amp;rdquo;&lt;/em&gt; is a phenomenon in psychology where
individuals agree that up until the current point in time they&amp;rsquo;ve
experienced continuous and significant growth, but believe that,
henceforth, they will not change by any considerable amount. This
illusion is persistent across all ages, and repeatedly proven to be
incorrect. We humans are malleable and never seem to solidify. No matter
where in life we are, we continue to develop, change, and grow.&lt;br&gt;
&lt;br&gt;
I was convinced that I&amp;rsquo;d learn a lot during my PhD, scientifically &amp;ndash;
but would I be affected on a personal level? Most likely not. Despite me
being aware of the aforementioned illusion, I was impermeable to the
idea that this experience would leave much of an imprint on me. I guess
that this is at its best described as arrogance and at its worst as
stupidity.&lt;br&gt;
&lt;br&gt;
Starting my PhD on the 12:th of June 2019, I&amp;rsquo;ve spent exactly 1010 days
&amp;ndash; or 2 years, 9 months, and 6 days &amp;ndash; pursuing my degree. This time has
been nothing short of transformative. Agreeably, approximately three
years is not a huge amount of time, but these years have been densely
packed with new experiences, encounters, and impressions. I&amp;rsquo;ve acquired
many new skills, but I also leave this era of my life as a very
different person than the one who entered it. Below follows a curated
list of insights that I&amp;rsquo;ve collected over the course of my PhD, relating
to science as well as personal topics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;A high level of complexity does not equal a high level of
success&lt;/strong&gt;&lt;/span&gt;. Among computational methods, it&amp;rsquo;s rarely the most
advanced methods that surface as the most popular ones. If you
desire spread and impact, study the field, seek questions that are
frequently being asked but rarely answered; then tailor your method
towards this. Never develop a method and &lt;em&gt;then&lt;/em&gt; invent a question
for it to address.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Develop for you audience, not yourself&lt;/strong&gt;&lt;/span&gt;. If you&amp;rsquo;re capable of
formulating a statistical or mathematical model, and then implement
it in code, you are likely more proficient in these areas than the
average user of your tool. Therefore, if you want people to use your
software, make the interface intuitive and provide a layman&amp;rsquo;s
explanation of how it works. Good documentation with loads of
examples is key to success. If possible, integrate your method into
already existing frameworks, this makes it easy for users to explore
without having to learn a new syntax. From my experience, methods
that are easy to operate are often favored over less user friendly
ones, even though the latter might have much better performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Listen to people when they complain&lt;/strong&gt;&lt;/span&gt;. If someone expresses that
they are struggling with something, they are likely not alone.
Embrace the opportunity and be the one to deliver the solution. This
is one of the easiest ways to identify areas where you can make a
useful contribution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Seek diversity and honor others&#39; expertise&lt;/strong&gt;&lt;/span&gt;. The best
collaborations are those where the people involved have
complementary strengths and show mutual respect for each other&amp;rsquo;s
skills. There&amp;rsquo;s a difference to being proud of your expertise and
being arrogant about it. A project thrives when the members don&amp;rsquo;t
consider their own contribution more (or less) important than anyone
else&amp;rsquo;s, but acknowledge that everyone is essential for the process
to move forward.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Time spent planning is often doubly rewarded.&lt;/strong&gt;&lt;/span&gt; I&amp;rsquo;m addicted to
fast progress, but have learnt that a short pause can save plenty of
time. Making informed design choices, and not just blindly throwing
yourself at the first idea, almost always results in a more pleasant
and faster overall process. A quick fix for the situation at hand
might seem tempting, but adapting general solutions usually pays off
in the end.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Garbage data will give you garbage results&lt;/strong&gt;&lt;/span&gt;. You wouldn&amp;rsquo;t pick up
a roadkill, cook it, and then expect it to taste like a dish from a
Michelin star restaurant. The same should hold true for data; one
needs to have reasonable expectations about what information that
can be derived from it. There&amp;rsquo;s a difference between a
bioinformat&lt;em&gt;ician&lt;/em&gt; and a mag&lt;em&gt;ician&lt;/em&gt;, the latter can turn nothing
into something, the former cannot. Sometimes, the data is just not
good enough to answer certain questions, if such is the case, there
are only two reasonable options: (i) ask a different question,
or (ii) generate new data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Don&amp;rsquo;t bring nuclear weapons to a gun fight.&lt;/strong&gt;&lt;/span&gt; Sometimes enthusiasm
and excitement about new powerful methods makes us blind to the fact
that the problem at hand likely could be solved with simpler means.
For some questions, a simple regression model will do just as fine
&amp;ndash; and possibly even better &amp;ndash; than a fancy deep learning model.
It&amp;rsquo;s easy to be caught up in the storm of buzz words, but take some
time to contemplate what level of complexity your problem actually
requires.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Aim to be the dumbest person in the room&lt;/strong&gt;.&lt;/span&gt; The best way to grow
is to position yourself in an environment where people are more
skilled than yourself, it accelerates learning and forces you to be
alert. Comfort is truly the enemy of improvement.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Don&amp;rsquo;t set yourself on fire to keep others warm&lt;/strong&gt;.&lt;/span&gt; I believe one
should always strive to help others when we can, but at some point,
it can also become problematic. If you &lt;em&gt;consistently&lt;/em&gt; are the one
who does the extra work, covers for others, and stays late &amp;ndash; then
you&amp;rsquo;re not helping, you&amp;rsquo;re being taken advantage of. We&amp;rsquo;re all
familiar with the airplane safety instructions telling us to put on
our own masks before helping someone else, this is equally
applicable to the workplace. If you want to have a positive impact
on the people around you, the most important thing is that you feel
good about your own situation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Never compromise on health&lt;/strong&gt;.&lt;/span&gt; In January 2021 I experienced
something close to a physical collapse, my body simply quit on me. I
could barely walk for two months, and for six more months, every day
of my life felt like a living hell &amp;ndash; I did not enjoy living. Every
morning, I put on an alarm that counted down the hours that I had
left to be awake and aware of my situation. Still, when night came,
I barely slept. Instead, I woke up multiple times having issues
breathing or in a state of complete sleep paralysis. A combination
of bad nutrition, an extreme (according to some people) amount of
exercise, and working ten to twelve hours a day (including weekends)
put me in a state of severe exhaustion. It was not until I became a
prisoner of my own body that I realized how much my previous freedom
meant to me. It&amp;rsquo;s hard realizing that you&amp;rsquo;re not an exception, but
just as human as everyone else. However, in the end, this
realization is healthy. If there&amp;rsquo;s one thing I will bring with me
from these years, it&amp;rsquo;s that &lt;em&gt;nothing&lt;/em&gt; is worth sacrificing one&amp;rsquo;s
well-being or health for.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Perspective is everything.&lt;/strong&gt;&lt;/span&gt; There&amp;rsquo;s a quote from the, truly
awful, series &lt;em&gt;&amp;ldquo;Pirates of the Caribbean&amp;rdquo;&lt;/em&gt; that reads: &lt;em&gt;&amp;ldquo;The problem
is not the problem. The problem is your attitude about the
problem.&amp;quot;&lt;/em&gt; Even though I cringe just by thinking about Captain Jack
Sparrow, these words have stayed with me. I&amp;rsquo;ve experienced first
hand how you can&amp;rsquo;t plan every aspect of life. Unexpected things can,
and will, happen. Our attitude determines how we experience these
events, whether it becomes a tragedy or a lesson. I&amp;rsquo;ve tried to
adopt more of a &amp;ldquo;gratitude mindset&amp;rdquo;; instead of being frustrated
when things don&amp;rsquo;t go my way, I try to celebrate what has gone right
so far. This attitude is not always easy to maintain, and one is of
course allowed to feel anger, but it&amp;rsquo;s a feeling that becomes toxic
if we let it linger for too long. Implementing this mindset have
made me a much happier individual and helped me through some really
dark times.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;what-i-predict&#34;&gt;What I predict&lt;/h1&gt;
&lt;p&gt;In 2016, when the Spatial Transcriptomics (ST) technique was published,
I had just finished the second year of my bachelor and was yet to hear
the term &amp;ldquo;transcriptomics&amp;rdquo;. Thus, I&amp;rsquo;m acutely aware of the fact that I
belong to the younger generation of the transcriptomics field, and do
not have the same experience as many of my peers. Still, having worked
somewhat intensively in the niche of computational method development
for spatial transcriptomics, I have a few predictions about the future,
which I&amp;rsquo;ll take the freedom to share here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Deep learning methods will become staple goods&lt;/strong&gt;&lt;/span&gt;. Although I&amp;rsquo;m
fascinated by deep learning (DL) methods, none of my works have so
far exploited the power of these architectures &amp;ndash; mainly because
I&amp;rsquo;ve felt as if the questions I had could be addressed with simpler
methods, or because the data wasn&amp;rsquo;t there. However, the trend of
access to more data, increasingly sophisticated and user friendly
frameworks &amp;ndash; paired with the development of new kinds of models &amp;ndash;
makes me certain that DL will revolutionize the single cell and
spatial transcriptomics fields, just as it has many other aspects of
our life. Currently, a lot of the DL-based methods simply apply
existing general models (e.g., taken from the natural language
processing field) to a problem in the transcriptomics sphere.
However, I believe we&amp;rsquo;ll migrate from this approach towards using
&lt;em&gt;bespoke models&lt;/em&gt;, where prior information about the biological
systems are integrated into the model architecture. In the very near
future, methods leveraging graph convolutional networks (GCNs) and
their aptitude for irregular data will likely become a popular
element in many methods for analysis of spatial transcriptomics
data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Emergence of perturbation studies.&lt;/strong&gt;&lt;/span&gt; The majority of publications
and projects that include spatial transcriptomics data have so far
been observational. A sample is collected, analyzed, and relevant
observations presented. At some rare occasions, samples representing
case and control exist, but usually with limited meta data and no
control over confounding variables. While interesting, this setup
mainly permits exploratory data analysis (EDA), but does not lend
itself well to infer causal relationships. To go beyond mere
associations or correlations, an intervention or &lt;em&gt;perturbation&lt;/em&gt; of
the system is necessary. Thus, I&amp;rsquo;m certain that it&amp;rsquo;s just a question
of time until techniques to the likes of Perturb-seq are combined
with spatial assays. With the introduction of perturbations, we&amp;rsquo;ll
be able to deduce how gene expression impacts spatial structure, and
potentially also the reciprocal relationships. With access to such
data, &lt;em&gt;causal inference&lt;/em&gt; will likely become an essential tool for
modeling and understanding causative effects. This is something I&amp;rsquo;m
genuinely excited about.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Preference of generative models.&lt;/strong&gt;&lt;/span&gt; Many of the models we currently
employ are of a discriminative nature, but I anticipate a shift
towards &lt;em&gt;generative models&lt;/em&gt;. Discriminative models assumes some
functional form of the posterior, in contrast, generative models
learns the joint probability distribution over all variables.
Generative models are more susceptible to incorporation of prior
information about the systems being studied, and better at
representing causal relationships. Thus, they neatly tie together
the two previous statement about a need for bespoke models and
causal links.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Challenges of multimodal analysis.&lt;/strong&gt;&lt;/span&gt; To me, the trend in
technology development can best be summarized with the Pokémon
slogan: &lt;em&gt;&amp;ldquo;Gotta Catch &amp;lsquo;Em All.&amp;quot;&lt;/em&gt; The transcriptome, epigenome,
proteome, and metabolome &amp;ndash; we want them all, at the same time, from
the same cell. Alas, 10x Genomics already have an assay where
RNA-seq and ATAC-seq data from the same cell can be obtained, as
well as an second assay where spatial RNA-seq information and
protein abundance are collected simultaneously. Except for increased
ability to resolve cell types and states, very few examples where
multimodal data is superior to unimodal data have so far been
presented, but there&amp;rsquo;s no lack of ideas.&lt;br&gt;
&lt;br&gt;
One of the commonly mentioned aspirations is to learn relationships
between the different modalities, which can be used to &lt;em&gt;predict&lt;/em&gt; one
modality from another, for example, deducing protein levels from
gene expression. Here, I will take a somewhat controversial and
conservative stance by stating that: prediction of one modality from
another will prove to be more challenging than many expect. I base
this statement on two concepts: &lt;em&gt;temporal delays&lt;/em&gt; and &lt;em&gt;missing
information&lt;/em&gt;. I&amp;rsquo;ll elaborate on both these issues below.&lt;br&gt;
&lt;br&gt;
Changes to one part of the central dogma usually don&amp;rsquo;t manifest
immediately in other parts, some form of delay tends to be present.
Thus, data ($x_t$) collected from one modality at time $t$
isn&amp;rsquo;t necessarily informative about the feature values ($y_t$)
of a different modality at the same time point. Instead &amp;ndash; due to
the lag &amp;ndash; $x_t$ relates to the values ($y_{t&amp;rsquo;}$) at a
later point $t&#39;$. This discrepancy causes an issue in learning,
because the two modalities are related according to:
$$y_{t&#39;} = f(x_t)$$
However, in most multimodal assays, we observe
$(x_t,y_t)$, meaning the data required to learn $f$ is not
available. Potentially, $y_{t&#39;}$ could be inferred from
$y_t$ by learning a second map $g$ such that
$y_{t&#39;} = g(y_t)$. Then $f$ can be learnt by first
transforming $y_t$ through $g$. Now, to find $g$, the
derivative $\partial y_{t}/\partial t$ must likely be deduced.
To estimate this derivative, at least one more data point close in
time (w.r.t. protein turnover timescales) is required.
Unfortunately, experimental assays only capture a single snapshot of
the system at a particular time. As a consequence, estimation of
such derivatives is usually infeasible. The dilemma described above
is what I refer to as temporal delay.&lt;br&gt;
&lt;br&gt;
Next, I&amp;rsquo;ll address the second caveat, that of missing data. The path
from one modality to another often involves several steps and
regulatory mechanisms, not exclusively relying on elements of the
observed modality. Thus, the previous equation should be updated to:
$$y_{t&#39;} = f(x_t,u_t)$$
Where $u_t$ represent entities with an
influence over the regulatory mechanisms (e.g., enzyme levels or
metabolic concentrations). Note that it&amp;rsquo;s possible that $u_t$ and
$y_t$ overlaps. Assuming that the above equation is true, data must also be collected on
$u_t$ for predictions about $y_{t&#39;}$ to be made, solely
relying on $x_t$ is not sufficient. Thus, $x_t$ does not
contain all the information needed to predict $y_t$. Of course,
if $t \approx t&#39;$ and $f(x_t,u_t) \approx f(x_t)$, the
problem is reduced to a much simpler one. Still, when such is not
the case, we should accept that the prediction task is challenging.
I definitely don&amp;rsquo;t think it&amp;rsquo;s beyond our capabilities, but while I
expect methods for *integration* of different data modalities to
emerge soon after the experimental technologies, general methods to
model intermodal relationships will take more time to mature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;The group before the individual.&lt;/strong&gt;&lt;/span&gt; As mentioned in the background, both
internal and external factors influence a cell&amp;rsquo;s state. In my opinion,
there&amp;rsquo;s still a need for general methods that tries to model how the local
environment of a cell affects its behavior. Conditional models for gene
expression already exist, one example being those that condition on cell
type, often resulting in sets of marker genes or gene signatures. These
models could be expanded to also include conditioning on the local
environment of a cell, for example, the proportion of different cell types
in its neighborhood. Such models add a new, interconnected, layer of
information to our understanding of how cells operate in biological systems.
Indeed, early attempts to construct models of this kind have already been
made (e.g., node-centric expression modeling by the Theis Lab), and I dare
to predict an abundance of them in a couple of years from now.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;what-i-hope&#34;&gt;What I hope&lt;/h1&gt;
&lt;p&gt;Having outlined the lessons I&amp;rsquo;ve learnt and my predictions for the
future, only one thing remains: listing some of the thing I hope for,
but am less certain of.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Revised educational programs.&lt;/strong&gt;&lt;/span&gt; In genomics, almost every new
technological method is accompanied by a suite of computational
tools to analyze the data. Ever more frequently, high impact
journals publish purely computational methods designed to unveil
previously occluded insights that only emerge by clever modeling of
the data. Thus, it&amp;rsquo;s evident that computational expertise is just as
important to advance life science as biological and technical
knowledge. If further proof is needed, in 2021, SciLifeLab and the
Wallenberg National Program announced several DDLS (data driven life
science) fellowships, acknowledging the importance of computational
competence. Still, the essential skills needed in computational
biology, such as: statistics, mathematics, probability theory,
modeling, and programming, are severely underrepresented in many of
the biotechnology programs at Swedish universities. We need to step
up our game if we want maintain our status within the life sciences
as an innovative and leading nation, and remain competitive with
international institutions like the Broad or the Wellcome Trust
Sanger Institute. The foundation must be laid early on, educating
PhD students is not good enough, computational biology tracks should
be instituted already at the Master level and potentially even seep
into the bachelor programs. I sincerely hope that the educational
programs will be updated, to also prepare students &amp;ndash; with an
interest &amp;ndash; for the challenges a computational biologist faces.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Increased diversity.&lt;/strong&gt;&lt;/span&gt; If there&amp;rsquo;s one thing I&amp;rsquo;m not stoked about,
it&amp;rsquo;s gender quotation and female-exclusive events; to me they have
an opposite effect of their intended purpose. These actions belittle
women&amp;rsquo;s competence and give the impression that we need extra help
or special rules to succeed. However, women are clearly
underrepresented in the computational field; at many hackathons or
meetings, I&amp;rsquo;ve found myself &amp;ndash; as a woman &amp;ndash; in a very small
minority, and am often assumed to be someone representing the
wet-lab side. I&amp;rsquo;m not upset by this, and have never been met with
anything but respect when correcting people, but I don&amp;rsquo;t think it
has to be like this. Girls and young women should be equally
encouraged to purse STEM subjects as their male counterparts, and
all of us &amp;ndash; me included &amp;ndash; should probably revise or abolish some
of our stereotypes. So, I dearly hope for a future where the
computational fields become more diverse and inclusive. Of course,
diversity extends beyond gender, the same arguments can &amp;ndash; and
should &amp;ndash; be made about ethnicity, age, religion, sexual identity,
etc. Being a white woman living in Sweden, I fully acknowledge my
privileges, and that my encounters with prejudice are probably
dwarfed by those from other &amp;ndash; less fortunate &amp;ndash; groups. Still, I
can only speak of my own experiences and observations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span style=&#34;color:#1eff00&#34;&gt;&lt;strong&gt;Breaking the limit&lt;/strong&gt;.&lt;/span&gt; My third, and final, wish for the future is
to pass the qualifying time for the Boston Marathon. To then &amp;ndash; of
course &amp;ndash; complete the race.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
